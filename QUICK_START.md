# ğŸš€ å¿«é€Ÿå¯åŠ¨æŒ‡å—

æ¬¢è¿ä½¿ç”¨ LLM å¤šè¯­è¨€å®‰å…¨è¯„ä¼°æ¡†æ¶ï¼æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨åœ¨ 5 åˆ†é’Ÿå†…å¼€å§‹ä½¿ç”¨ã€‚

## 1ï¸âƒ£ å®‰è£…ï¼ˆ1åˆ†é’Ÿï¼‰

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd C:/llm-multilingual-safety-eval

# å®‰è£…æ¡†æ¶
pip install -e .
```

## 2ï¸âƒ£ è¿è¡Œæ¼”ç¤ºï¼ˆ2åˆ†é’Ÿï¼‰

```bash
# è¿è¡Œå¿«é€Ÿæ¼”ç¤º
python demo.py
```

è¿™å°†å±•ç¤ºæ¡†æ¶çš„åŸºæœ¬åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- åŠ è½½æ¨¡å‹
- è¿è¡Œå®‰å…¨è¯„ä¼°
- åˆ†æç»“æœ
- ç”ŸæˆæŠ¥å‘Š

## 3ï¸âƒ£ ç¬¬ä¸€æ¬¡çœŸå®è¯„ä¼°ï¼ˆ2åˆ†é’Ÿï¼‰

### é€‰é¡¹ A: ä½¿ç”¨å‘½ä»¤è¡Œ

```bash
# è¯„ä¼° Claude æ¨¡å‹
lmse evaluate --model claude-3-opus --languages chinese --domains healthcare

# æ³¨æ„ï¼šéœ€è¦å…ˆè®¾ç½® API å¯†é’¥
export ANTHROPIC_API_KEY="your-api-key"
```

### é€‰é¡¹ B: ä½¿ç”¨ Python

```python
from lmse import SafetyEvaluator, ModelLoader

# åŠ è½½æ¨¡å‹
model = ModelLoader.load("claude-3-opus", api_key="your-key")

# è¿è¡Œè¯„ä¼°
evaluator = SafetyEvaluator("configs/default.yaml")
results = evaluator.evaluate(model, languages=["chinese"])

# æŸ¥çœ‹ç»“æœ
print(f"å®‰å…¨è¯„åˆ†: {results['safety_score'].mean():.1f}")
```

## ğŸ“Š æŸ¥çœ‹ç»“æœ

è¯„ä¼°å®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š

1. **æŸ¥çœ‹ CSV ç»“æœ**
   ```
   results/evaluation_*.csv
   ```

2. **æ‰“å¼€ HTML æŠ¥å‘Š**
   ```
   results/report_*.html
   ```

3. **ä½¿ç”¨ Jupyter ç¬”è®°æœ¬**
   ```bash
   jupyter lab visualizations/analysis_dashboard.ipynb
   ```

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **æ¢ç´¢æ›´å¤šè¯­è¨€**
   ```bash
   lmse list-scenarios --format table
   ```

2. **æ¯”è¾ƒå¤šä¸ªæ¨¡å‹**
   ```bash
   python examples/model_comparison.py
   ```

3. **è‡ªå®šä¹‰è¯„ä¼°**
   - ç¼–è¾‘ `configs/default.yaml`
   - æ·»åŠ è‡ªå·±çš„åœºæ™¯åˆ° `datasets/scenarios/`

## â“ éœ€è¦å¸®åŠ©ï¼Ÿ

- ğŸ“š æŸ¥çœ‹å®Œæ•´æ–‡æ¡£: `docs/`
- ğŸ’¡ å‚è€ƒç¤ºä¾‹ä»£ç : `examples/`
- ğŸ› æŠ¥å‘Šé—®é¢˜: åˆ›å»º GitHub Issue

---

**æç¤º**: ä½¿ç”¨ `lmse --help` æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤ï¼

ç¥æ‚¨è¯„ä¼°æ„‰å¿«ï¼ ğŸ‰